{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8724e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04def9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The methods you used in your experiments\n",
    "methods = [\"SGD\", \"DPSGD\", \"DPSGD_noise\", \"DPSGD_clip\"]\n",
    "\n",
    "methods_to_colours = {\n",
    "    \"SGD\" : \"#66c2a5\",\n",
    "    \"DPSGD\" : \"#fc8d62\",\n",
    "    \"DPSGD_n3\" : \"#8da0cb\",\n",
    "    \"DPSGD_noise\" : \"#e78ac3\",\n",
    "    \"DPSGD_noise5\" : \"#e5c494\",\n",
    "    \"DPSGD_noise10\" : \"#b3b3b3\",\n",
    "    \"DPSGD_clip\" : \"#e5c494\",\n",
    "    \"DPSGDGA\" : \"#ffd92f\",\n",
    "    \"DPSGDG\" : \"#3633FF\"\n",
    "}\n",
    "\n",
    "# The types of attacks\n",
    "attacks = {\n",
    "    \"pgd\" : \"linf\",\n",
    "    \"fgsm\" : \"linf\", \n",
    "    \"pgdl2\" : \"l2\",\n",
    "    \"deepfooll2\" : \"l2\",\n",
    "    \"deepfoollinf\" : \"linf\",\n",
    "#     \"boundary\" : \"l2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6dbe33",
   "metadata": {},
   "source": [
    "The following method is for reading robustness per method. You need the robustness results by setting `--config valid_metrics='accuracy','robustness_succ'` and then pass the path of experiment results to `read_robustness_per_method`. For example, you have a the following folder which contains the results for different methods:\n",
    "```\n",
    "├──FoolBox_exps:\n",
    "    ├──mnist_DPSGD,\n",
    "    ├──mnist_DPSGD_clip,\n",
    "    ├──mnist_DPSGDA,\n",
    "    ├──mnist_DPSGD_n3,\n",
    "    ├──mnist_DPSGD_noise,\n",
    "    ├──mnist_SGD\n",
    "```\n",
    "Then you can parse all the results and plot them\n",
    "```\n",
    "df_ra = read_robustness_per_method(path_to_FoolBox_exps, root_dir=None, methods=methods)\n",
    "plot_epoch_robustness_per_gamma(df=df_ra, epoch=-1, methods=methods) # You can also specify a particular attack\n",
    "plot_robustness_per_epoch_per_gamma(df=df_ra, methods=methods, attacks=[\"deepfooll2\", \"deepfoollinf\"])\n",
    "plot_epoch_attack_norm_per_gamma(df=df_ra, attack=\"DeepFool\", methods=methods, epoch=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass attacks as dict with atk : norm\n",
    "\n",
    "# if robustness_acc only on for test_metrics: returns dictionary, method : list of length 1\n",
    "# if robustness_acc only on for valid_metrics: returns dictionary, method : list of length max_epochs + 1 or max_epochs\n",
    "# (accounting for if we do evalution before training)\n",
    "# if robustness_acc on for both valid_metrics and test_metrics: returns dictionary, method : list of length max_epochs + 2 or max_epochs + 1\n",
    "\n",
    "def read_robustness_per_method(dir_name, root_dir=None, methods=methods, attacks=attacks):\n",
    "    robustness_per_method = {}\n",
    "    for method in methods:\n",
    "        if root_dir is None:\n",
    "            output_path = os.path.join(dir_name, f\"mnist_{method}\", \"stdout\")\n",
    "            config_path = os.path.join(dir_name, f\"mnist_{method}\", \"config.json\")\n",
    "        else:\n",
    "            output_path = os.path.join(root_dir, dir_name, f\"mnist_{method}\", \"stdout\")\n",
    "            config_path = os.path.join(root_dir, dir_name, f\"mnist_{method}\", \"config.json\")\n",
    "        config_file = open(config_path)\n",
    "        config = json.load(config_file)\n",
    "        config_file.close()\n",
    "        config = {k.lower() : config[k] for k in config.keys()}\n",
    "\n",
    "        # get gammas_l2, gammas_linf keys\n",
    "        gammas_l2 = config[\"gammas_l2\"]\n",
    "        gammas_linf = config[\"gammas_linf\"]\n",
    "\n",
    "        method_robustness_per_epoch = []\n",
    "        counter = 0\n",
    "\n",
    "        with open(output_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if re.search(r\".robustness_succ\", line) and (re.match(\"Validating\", line) or re.match(\"Testing\", line)):\n",
    "                    index = pd.MultiIndex.from_tuples([], names=(\"attack\", \"gamma\"))\n",
    "                    robustness_per_attack = pd.DataFrame(columns=[\"acc\", \"l2\", \"linf\", \"l2_miss\", \"linf_miss\"], index=index)\n",
    "                    method_robustness_per_epoch.append(robustness_per_attack) # at index counter\n",
    "                    counter += 1\n",
    "\n",
    "                if re.match(r'adv robust succ on.*', line):\n",
    "                    metric = re.match(r'adv robust succ on (.*): \\[(.*)\\], l2 norm: \\[(.*)\\], linfty norm: \\[(.*)\\], l2 norm miss: \\[(.*)\\], linfty norm miss: \\[(.*)\\]', line)\n",
    "                    attack = metric.group(1)\n",
    "                    if not attack in attacks:\n",
    "                        continue\n",
    "\n",
    "                    def str_to_list(s, r=5):\n",
    "                        return [round(float(x),r) for x in s.replace(\" \",\"\").split(\",\")]\n",
    "\n",
    "                    (acc, l2_norm, linf_norm, l2_norm_miss, linf_norm_miss) = (str_to_list(metric.group(i)) for i in range(2,6+1))\n",
    "\n",
    "                    # get norm, gamma based on attack\n",
    "                    norm = attacks[attack]\n",
    "                    if norm == \"linf\":\n",
    "                        gammas = gammas_linf\n",
    "                    else: gammas = gammas_l2\n",
    "\n",
    "                    for g, gamma in enumerate(gammas):\n",
    "                        # convert from adversarial success to adversarial accuracy for consistency\n",
    "                        row = [1-acc[g], l2_norm[g], linf_norm[g], l2_norm_miss[g], linf_norm_miss[g]]\n",
    "                        method_robustness_per_epoch[counter - 1].loc[(attack,gamma),:] = row\n",
    "                        \n",
    "        robustness_per_method[method] = method_robustness_per_epoch\n",
    "    return robustness_per_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8885f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: df = LeNet, dict: method : df\n",
    "# columns= [\"acc\", \"l2\", \"linf\", \"l2_miss\", \"linf_miss\"]\n",
    "# index = [\"attack\", \"gamma\"]\n",
    "def plot_epoch_robustness_per_gamma(df=ra_LeNet, methods=methods, attacks=attacks, epoch=-1):\n",
    "    fig, axs = plt.subplots(1, len(attacks), figsize=(20,5), sharey=True, dpi=75)\n",
    "\n",
    "    for i,(attack,norm) in enumerate(attacks.items()):\n",
    "        col = norm\n",
    "        if attack == \"deepfooll2\": col = \"l2_miss\"\n",
    "        elif attack == \"deepfoollinf\": col = \"linf_miss\"\n",
    "\n",
    "        for method in methods:\n",
    "            df_method = df[method][epoch]\n",
    "            # check attack exists for method at this epoch\n",
    "            if not attack in df_method.index:\n",
    "                continue\n",
    "            df_method = df[method][epoch].loc[attack]\n",
    "            x = list(df_method[col])\n",
    "            y = list(df_method[\"acc\"])\n",
    "            axs[i].plot(x,y,\"o-\",c=methods_to_colours[method], alpha=0.7, label=method)\n",
    "\n",
    "        axs[i].set_xlabel(f\"{norm} norm\")\n",
    "        axs[i].set_title(attack)\n",
    "        if i == 0: \n",
    "            axs[i].set_ylabel(\"Adversarial accuracy\")\n",
    "            axs[i].legend()\n",
    "\n",
    "    fig.suptitle(\"Adv acc on LeNet, varying adv strength\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15495024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_robustness_per_epoch_per_gamma(df=ra_LeNet, methods=methods, attacks=attacks, column=\"acc\"):\n",
    "    gammas_per_attack = [df[methods[0]][0].loc[attack].index.tolist() for attack in attacks]\n",
    "    n = max([len(gammas) for gammas in gammas_per_attack])\n",
    "    m = len(attacks)\n",
    "\n",
    "    # TODO: make figsize depend on n,m\n",
    "    fig, axs = plt.subplots(n, m, figsize=(8,20), dpi=100, sharex=True)\n",
    "\n",
    "    for i, attack in enumerate(attacks):\n",
    "        gammas = gammas_per_attack[i]\n",
    "        for k, gamma in enumerate(gammas):\n",
    "\n",
    "            for j, method in enumerate(methods):\n",
    "                data = [epoch[column].loc[attack,gamma] for epoch in df[method]]\n",
    "                axs[k][i].plot(data, label=method, c=methods_to_colours[method], alpha=0.7)\n",
    "\n",
    "            if k == 0:\n",
    "                axs[k][i].set_title(attack)\n",
    "            if k == len(gammas) - 1:\n",
    "                axs[k][i].legend()\n",
    "\n",
    "            axs[k][i].set_ylabel(f\"Adv. {column} @ {gamma}\")\n",
    "            if k == len(gammas) - 1: axs[k][i].set_xlabel(\"Epochs\") # doesnt plot for all rows\n",
    "# NOTE: might plot final robustness twice, if it is evaluated in both valid_metrics and test_metrics\n",
    "    fig.suptitle(f\"{column} over training\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: df = LeNet, dict: method : df\n",
    "# columns= [\"acc\", \"l2\", \"linf\", \"l2_miss\", \"linf_miss\"]\n",
    "# index = [\"attack\", \"gamma\"]\n",
    "def plot_epoch_attack_norm_per_gamma(df=ra_LeNet, attack=\"DeepFool\", methods=methods, epoch=-1):\n",
    "    if attack == \"DeepFool\":\n",
    "        attacks = [\"deepfooll2\",\"deepfoollinf\"]\n",
    "    else:\n",
    "        attacks = [attack]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5), dpi=75)\n",
    "    axs2 = [ax.twinx() for ax in axs]\n",
    "    for ax in axs2:\n",
    "        ax.set_ylim((0,1))\n",
    "        ax.set_ylabel(\"Adv acc\")\n",
    "        ax.grid(False)\n",
    "\n",
    "    for i,iattack in enumerate(attacks):\n",
    "        # TODO: use this using the attack dictionary\n",
    "        if iattack == \"deepfooll2\": norm = \"l2\"\n",
    "        elif iattack == \"deepfoollinf\": norm = \"linf\"\n",
    "        else: norm = \"l2\" # NOTE: assuming this is boundary attack\n",
    "        col = f\"{norm}_miss\"\n",
    "\n",
    "        for j,method in enumerate(methods):\n",
    "            df_method = df[method][epoch].loc[iattack]\n",
    "            y = df_method[col]\n",
    "            axs[i].plot(y,\"o-\",c=methods_to_colours[method],label=method)\n",
    "            axs2[i].plot(df_method[\"acc\"],\"o--\",c=methods_to_colours[method], alpha=0.5,label=method)\n",
    "\n",
    "        axs[i].set_xlabel(\"gamma\")\n",
    "        axs[i].set_title(iattack)\n",
    "        axs[i].set_ylabel(f\"Perturbation norm {norm}\")\n",
    "        axs[i].legend()\n",
    "\n",
    "    fig.suptitle(f\"Distance to decision boundary ({attack}), LeNet, varying adv strength\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b55e31",
   "metadata": {},
   "source": [
    "The following method is for reading and plotting accuracy or loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b905e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_per_method(metric, dir_name, root_dir=None, methods=methods):\n",
    "    # ACCURACY\n",
    "    if metric == \"accuracy\": # evaluated on validation = test set\n",
    "        test_loss_per_method = {}\n",
    "        for method in methods:\n",
    "            if root_dir is None:\n",
    "                output_path = os.path.join(dir_name, f\"mnist_{method}\", \"stdout\")\n",
    "            else:\n",
    "                output_path = os.path.join(root_dir, dir_name, f\"mnist_{method}\", \"stdout\")\n",
    "            epoch = 0\n",
    "            test_loss = []\n",
    "            with open(output_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if re.match(r'Validation\\saccuracy.*', line):\n",
    "                        metric = re.match(r'Validation\\saccuracy:\\s(.*)', line).group(1)\n",
    "                        test_loss.append(round(float(metric), 4)) \n",
    "                        epoch += 1\n",
    "            test_loss_per_method[method] = test_loss\n",
    "        for method in methods:\n",
    "            plt.plot(test_loss_per_method[method], label=method, c=methods_to_colours[method], alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.title(\"Validation accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        return test_loss_per_method\n",
    "\n",
    "    # LOSS\n",
    "    if metric == \"loss\": # evaluated on training set\n",
    "        train_loss_per_method = {}\n",
    "        for method in methods:\n",
    "            if root_dir is None:\n",
    "                output_path = os.path.join(dir_name, f\"mnist_{method}\", \"train_loss_per_epochs.csv\")\n",
    "            else:\n",
    "                output_path = os.path.join(root_dir, dir_name, f\"mnist_{method}\", \"train_loss_per_epochs.csv\")\n",
    "            loss = pd.read_csv(output_path).train_loss.tolist()\n",
    "            train_loss_per_method[method] = loss\n",
    "        for method in methods:\n",
    "            plt.plot(train_loss_per_method[method], label=method, c=methods_to_colours[method], alpha=0.5)\n",
    "        plt.legend()\n",
    "        plt.title(\"Train loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        return train_loss_per_method\n",
    "\n",
    "    return (f\"Invalid metric {metric}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165a939",
   "metadata": {},
   "source": [
    "The following mehtods are only for reading different CSV files and plotting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fcf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_max_mean_gradient(dir_name, methods):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,5), dpi=75)\n",
    "    \n",
    "    for method in methods:\n",
    "        max_grad_path = os.path.join(dir_name, f\"mnist_{method}\", \"max_grad_norms_per_epochs.csv\")\n",
    "        avg_grad_path = os.path.join(dir_name, f\"mnist_{method}\", \"avg_grad_norms_per_epochs.csv\")\n",
    "        \n",
    "        max_grad_df = pd.read_csv(max_grad_path)[\"max_grads\"]\n",
    "        avg_grad_df = pd.read_csv(avg_grad_path)[\"ave_grads\"]\n",
    "        \n",
    "        axs[0].plot(max_grad_df, label=method, c=methods_to_colours[method], alpha=0.7)\n",
    "        axs[1].plot(avg_grad_df, label=method, c=methods_to_colours[method], alpha=0.7)\n",
    "        \n",
    "    axs[0].set_ylabel(\"max grad\")\n",
    "    axs[0].set_xlabel(\"epoch\")\n",
    "    axs[0].set_title(\"Max Gradient\")\n",
    "    axs[1].set_ylabel(\"avg grad\")\n",
    "    axs[1].set_xlabel(\"epoch\")\n",
    "    axs[1].set_title(\"Average Gradient\")\n",
    "    axs[0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_norm_of_avg_grad(dir_name, methods):\n",
    "    for method in methods:\n",
    "        norm_avg_grad_path = os.path.join(dir_name, f\"mnist_{method}\", \"norm_avg_grad_per_epochs.csv\")\n",
    "        norm_avg_grad_df = pd.read_csv(norm_avg_grad_path)[\"gorm_avg_grad\"]\n",
    "        plt.plot(norm_avg_grad_df, label=method, c=methods_to_colours[method], alpha=0.7)\n",
    "    plt.ylabel(\"grad norm\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.title(\"Norm of Average Gradient\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1bf7d",
   "metadata": {},
   "source": [
    "### Hessian, grad values over training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8f6a7",
   "metadata": {},
   "source": [
    "At some iteration  𝑖 , we have batch  𝐵  and for some  𝑥∈𝐵 , we compute  ∇𝑥(ℓ(𝑓𝜃(𝑥)),𝑦)  and  ∇2𝑥(ℓ(𝑓𝜃(𝑥)),𝑦) . Then the grad_term is  ‖∇𝑥(ℓ(𝑓𝜃(𝑥)),𝑦)‖2  and the Hessian term is  𝜆max(∇2𝑥(ℓ(𝑓𝜃(𝑥)),𝑦)) . For each epoch and last batch (on training set), we compute the average of the grad term and hessian term, and similarly with the max."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94b866",
   "metadata": {},
   "source": [
    "2012.07985 computes Hessian (for final model) for 100 random test samples and shows 15 largers eigenvalues (presumed averaged over the 100 samples). They see that DPSGD largest eigenvalues are up to 100x larger than SGD largest eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_adv_loss(dir_name, root_dir=None, methods=methods):\n",
    "    exp_adv_loss_per_method = {}\n",
    "    for method in methods:\n",
    "        if root_dir is None:\n",
    "            adv_loss_path = os.path.join(dir_name, f\"mnist_{method}\", \"expected_adversarial_loss_per_epochs.csv\")\n",
    "        else:\n",
    "            adv_loss_path = os.path.join(root_dir, dir_name, f\"mnist_{method}\", \"expected_adversarial_loss_per_epochs.csv\")\n",
    "        df = pd.read_csv(adv_loss_path)\n",
    "        df.drop(columns=\"batch\", inplace=True)\n",
    "        df.set_index(\"epoch\", inplace=True) # NOTE: assumign eval only happens for one batch in epoch\n",
    "        exp_adv_loss_per_method[method] = df\n",
    "\n",
    "    return exp_adv_loss_per_method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ff9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_hessians(df, methods=methods):\n",
    "    fig, axs = plt.subplots(1,4,figsize=(18,5),dpi=75, sharex=True) # len(columns), len(methods)\n",
    "\n",
    "    for j, method in enumerate(methods): # pass\n",
    "        for i,column in enumerate(df[method].columns):        \n",
    "            axs[i].set_title(column)\n",
    "            axs[i].set_ylabel(column)\n",
    "            axs[i].set_xlabel(\"Epochs\")\n",
    "            axs[i].plot(df[method][column], 'o', c=methods_to_colours[method], alpha=0.8, label=method)#, color=colors[j])\n",
    "            # line of best fit:\n",
    "            #x = df[method][column].index.values\n",
    "            #y = df[method][column].values\n",
    "            #axs[i].plot(x, np.poly1d(np.polyfit(x, y, 1))(x), color=colors[j])\n",
    "            if i == 0: axs[i].legend()\n",
    "    \n",
    "    fig.suptitle(\"Hessian,grad values over training;\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = get_exp_adv_loss(\"path to directory\", root_dir=\"\", methods=methods)\n",
    "plot_grad_hessians(df, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_max_lambda(dir_name, root_dir=None, methods=methods):\n",
    "    exp_max_lambda = {}\n",
    "    for method in methods:\n",
    "        for seed in range(3):\n",
    "            if root_dir is None:\n",
    "                adv_loss_path = os.path.join(dir_name, f\"{seed}/mnist_{method}\", \"params_max_eigenval_per_epochs.csv\")\n",
    "            else:\n",
    "                adv_loss_path = os.path.join(root_dir, dir_name, f\"{seed}/mnist_{method}\", \"params_max_eigenval_per_epochs.csv\")\n",
    "            df = pd.read_csv(adv_loss_path)['max_eigenval']\n",
    "#             df.drop(columns=\"batch\", inplace=True)\n",
    "        df.set_index(\"epoch\", inplace=True) # NOTE: assumign eval only happens for one batch in epoch\n",
    "        exp_max_lambda[method] = df\n",
    "\n",
    "    return exp_max_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_param_lambda(df=lambda_LeNet, methods=methods):\n",
    "\n",
    "    for j, method in enumerate(methods): # pass\n",
    "        for i,column in enumerate(df[method].columns):\n",
    "            x = df[method][column].index.values\n",
    "            y = df[method][column].values\n",
    "            plt.plot(x, y, label=method, c=methods_to_colours[method], alpha=0.5)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Parameters' max eigenvalues over training; LeNet\")\n",
    "    plt.xlabel(\"Epochs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
